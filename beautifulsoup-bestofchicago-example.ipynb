{
 "metadata": {
  "name": "",
  "signature": "sha256:538629f9374d79017055fb667e57c8ceec55d40171df780b92dcc84a47f64316"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Introduction\n",
      "\n",
      "This workshop will be easier to follow if you have some familiarity with BeautifulSoup documentation or if you refer to it as you go :  \n",
      "\n",
      "  http://beautiful-soup-4.readthedocs.org/en/latest/# \n",
      "\n",
      "# Acknowledgment\n",
      "\n",
      "This workshop is inspired from the following tutorial and Github Gist python script :   \n",
      "\n",
      "  http://www.gregreda.com/2013/03/03/web-scraping-101-with-python/#http://www.popsugar.com/Celebrities-Using-Instagram-21244293#opening-slide  \n",
      "  \n",
      "  https://gist.github.com/gjreda/f3e6875f869779ec03db  \n",
      "\n",
      "# Adaptations\n",
      "\n",
      "the following adaptations have been made :  \n",
      "\n",
      "* we are using the html5lib library instead of the lxml librar. Being purely python with no requirement for cpython or libxml2 and libxslt c libraries,  html5lib seems easier to install than lxml, and for the purpose of this workshop  did not seem to incur a prohibitive performance penalty\n",
      "\n",
      "* the target website used as an example has been modified since the original post was published. \n",
      "\n",
      "  * the first website page processed now has different DOM structure: the section of interest within which the urls are searched for can no longer be recognized as a dl tag with \"boccat\" class. Instead we will here directly identify all the links of interests by taking advantage of the fact they can be recognized as div tags with a 'BestOfItem' class  \n",
      "  * the second tyoe of website pages processed also now has different DOM structure: the runners_up are no longer in a tag inside of the h2 tag. Instead we find them moving up to the parent of the h2 tag and looking at the first li tag within that\n",
      "\n",
      "# Setup prerequisites\n",
      "\n",
      "We assume that you either have performed the setup as described in SETUP_INSTRUCTIONS.md, or you have performed an equivalent alternative setup of your choice, including a version of python, a choice of interactive python interpreter and the following pypi packages: beautifulsoup4, html5lib"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from bs4 import BeautifulSoup\n",
      "from urllib2 import urlopen   # this will help in opening HTTP URLs\n",
      "from time import sleep        # this will help slow down our scraping to be nice with our target websites"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# utility funtiom to parse a given url with html5 librry and make and return a bs4.BeautifulSoup object out of it\n",
      "def make_soup(url):\n",
      "    html = urlopen(url).read()\n",
      "    return BeautifulSoup(html, \"html5lib\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# lets try the make_soup function on our target website home page:  \n",
      "HOMEPAGE_URL = \"http://www.chicagoreader.com\"\n",
      "homesoup=make_soup(HOMEPAGE_URL)\n",
      "type(homesoup)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(homesoup)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[ child.name for child in homesoup ]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(homesoup.body)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[ child.name for child in homesoup.body ]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "homesoup"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# accessing a particular tag, the body tag\n",
      "homesoup.body"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# accessing a script tag\n",
      "# there are several script tags, we get the first one\n",
      "homesoup.script"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      " # we can use a hierarchy of tags to zoom in on the one we want  \n",
      "# let's skip any tags in head, and get the first script tag inside body:  \n",
      "homesoup.body.script"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# there are several ul tags, let's get the first one\n",
      "homesoup.ul"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# we can get the list of the ul tags\n",
      "len(homesoup.body.find_all('ul'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# there is an alternative syntax to the find_all method:  \n",
      "# treat the tag as a function and call it with the same argument that were given to find_all  \n",
      "len(homesoup.body('ul'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# we can get the 12th item the list of the ul tags\n",
      "homesoup.body('ul')[12]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# There are 6 different categies \n",
      "# for each category there is a page that presents (inside the \"Reader's Picks\" box) a list of links\n",
      "# each link in such a list leads to the details of the winners for a subcategory within that category\n",
      "# For example the FoodAndDrink category is currently (we are in year 2104) found at this url: \n",
      "# http://www.chicagoreader.com/chicago/BestOf?category=1979894&year=2014\n",
      "# lets have a look at it as viewed in a browser \n",
      "from IPython.display import HTML\n",
      "HTML('<iframe src=http://www.chicagoreader.com/chicago/BestOf?category=1979894&year=2014 width=900 height=1500></iframe>')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# let's define a dictionary to hold the various urls we are interested in scraping:  \n",
      "BESTOF_URLS={}\n",
      "BESTOF_URLS[\"ArtsAndCulture\"]=\"http://www.chicagoreader.com/chicago/BestOf?category=4053660&year=2014\"\n",
      "BESTOF_URLS[\"FoodAndDrink\"]  =\"http://www.chicagoreader.com/chicago/BestOf?category=1979894&year=2014\"\n",
      "BESTOF_URLS[\"CityLife\"]=\"http://www.chicagoreader.com/chicago/BestOf?category=4053661&year=2014\"\n",
      "BESTOF_URLS[\"MusicAndNightlife\"]=\"http://www.chicagoreader.com/chicago/BestOf?category=4053658&year=2014\"\n",
      "BESTOF_URLS[\"GoodsAndServices\"]=\"http://www.chicagoreader.com/chicago/BestOf?category=1979897&year=2014\"\n",
      "BESTOF_URLS[\"SportsAndRec\"]=\"http://www.chicagoreader.com/chicago/BestOf?category=1979898&year=2014\"\n",
      "# let's see what this dictionary looks like  \n",
      "print BESTOF_URLS\n",
      "# and let's use it to facilitate preparing one kind of soup  \n",
      "make_soup(BESTOF_URLS[\"ArtsAndCulture\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# noticing that the structure of these BestOf urls include a year parameter as well as a coded values for a cateory parameter,\n",
      "# let's take advantage of this to facilitate even more the preparation of different flavors and millesimes of soups  \n",
      "# let's define a dictionary to hold the category codes for the various urls we are interested in scraping:  \n",
      "CATEGORYCODES={}\n",
      "CATEGORYCODES[\"ArtsAndCulture\"   ]=\"4053660\"\n",
      "CATEGORYCODES[\"FoodAndDrink\"     ]=\"1979894\"\n",
      "CATEGORYCODES[\"CityLife\"         ]=\"4053661\"\n",
      "CATEGORYCODES[\"MusicAndNightlife\"]=\"4053658\"\n",
      "CATEGORYCODES[\"GoodsAndServices\" ]=\"1979897\"\n",
      "CATEGORYCODES[\"SportsAndRec\"     ]=\"1979898\"\n",
      "# let's see what that looks like\n",
      "print CATEGORYCODES"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# now let's generalize by defining this function\n",
      "def bestofurl(category,year='2014'):\n",
      "    \"\"\"returns a url for the chicagoreader best of page for a given category and  a given year, \n",
      "    category is one of: 'MusicAndNightlife', 'GoodsAndServices', 'ArtsAndCulture', \n",
      "    'SportsAndRec', 'FoodAndDrink', 'CityLife'\n",
      "    year defaults to '2014'\"\"\"\n",
      "    return 'http://www.chicagoreader.com/chicago/BestOf?category=' + CATEGORYCODES[category] + '&year=' + year\n",
      "# let's see how this works\n",
      "print bestofurl('CityLife','2012')\n",
      "print bestofurl('CityLife')\n",
      "# lets make an oldie soup\n",
      "make_soup(bestofurl(\"SportsAndRec\",'2011'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# let's take as example the category 'FoodAndDrink' \n",
      "# we start by getting and turning into soup the webpage for that category\n",
      "olympianartistsoup=make_soup(bestofurl('ArtsAndCulture','2012'))\n",
      "# we want to extract out of that soup a list of all the links to detail pages about winners for each subcategory\n",
      "# so we first get all the div tags that have class 'bestOfItem'\n",
      "olympianartistdivtags= olympianartistsoup('div',class_=\"bestOfItem\")\n",
      "# for each tag found, we get the href and build a list of all these hrefs\n",
      "[divtag.a['href'] for divtag in olympianartistdivtags]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# lets generalize the example we just saw into a function \n",
      "# this function takes 2 arguments, category and year, \n",
      "# and returns the list of urls to the detail pages about winners in each subcategory \n",
      "def get_category_links(category,year='2014'):\n",
      "    \"\"\"returns a list of urls to the detail pages about winners in each subcategory \n",
      "    found in the chicagoreader best of page for a given category and a given year, \n",
      "    category is one of:\n",
      "    'MusicAndNightlife', 'GoodsAndServices', 'ArtsAndCulture', \n",
      "    'SportsAndRec', 'FoodAndDrink', 'CityLife'\n",
      "    year defaults to '2014'\"\"\"\n",
      "    soup=make_soup(bestofurl(category,year))\n",
      "    divtags= soup('div',class_=\"bestOfItem\")\n",
      "    return [divtag.a['href'] for divtag in divtags]\n",
      "\n",
      "# let's try it\n",
      "get_category_links('SportsAndRec','2011')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# let's try again\n",
      "get_category_links('FoodAndDrink','2014')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# let's try again\n",
      "get_category_links('CityLife','2010')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# let's try again\n",
      "get_category_links('CityLife','2011')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# let's try again\n",
      "get_category_links('CityLife','2012')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# let's try again\n",
      "get_category_links('CityLife','2013')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# let's try again\n",
      "get_category_links('CityLife','2014')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Ok, we now are able to retrieve the url leading to the detail page about winners for all subcategories of any given category in a given year\n",
      "# let's have a lok at one such page \n",
      "# in the previous list for 'CityLife','2011' you can see this first subcategotry link\n",
      "# http://www.chicagoreader.com/chicago/best-fulminator-on-facebook/BestOf?oid=4101957\n",
      "# lets have a look at it as viewed in a browser \n",
      "from IPython.display import HTML\n",
      "HTML('<iframe src=http://www.chicagoreader.com/chicago/best-fulminator-on-facebook/BestOf?oid=4101957 width=900 height=900></iframe>')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# using this page as an example, let's see what information we would like to grab and how to go about it:\n",
      "# we first prepare our soup\n",
      "fancywinnersoup=make_soup('http://www.chicagoreader.com/chicago/best-fancy-restaurant/BestOf?oid=13794959')\n",
      "# let's get hold og the subcategory name\n",
      "print fancywinnersoup.find(\"h1\", \"headline\").string\n",
      "# let's get hold of the winner(s), there might be more then one, so we build a list\n",
      "print [h2.string for h2 in fancywinnersoup.findAll(\"h2\", \"subheadline\")]\n",
      "# let's get hold of the almost-winner(s), there might be more then one, so we build a list\n",
      "print [h2.parent.li.string for h2 in fancywinnersoup.findAll(\"h2\",\"heading\")]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# let's using another page as an example, \n",
      "# let's see what information we would like to grab and how to go about it:\n",
      "# we first prepare our soup\n",
      "reappearingwinnersoup=make_soup('http://www.chicagoreader.com/chicago/best-reappearing-act/BestOf?oid=13795515')\n",
      "# let's get hold og the subcategory name\n",
      "print reappearingwinnersoup.find(\"h1\", \"headline\").string\n",
      "# let's get hold of the winner(s), there might be more then one, so we build a list\n",
      "print [h2.string for h2 in reappearingwinnersoup.findAll(\"h2\", \"subheadline\")]\n",
      "# let's get hold of the almost-winner(s), there might be more then one, so we build a list\n",
      "print [h2.parent.li.string for h2 in reappearingwinnersoup.findAll(\"h2\",\"heading\")]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_category_winner(winnerurl):\n",
      "    winnersoup = make_soup(winnerurl)\n",
      "    category   = winnersoup.find(\"h1\", \"headline\").string\n",
      "    winner     = [h2.string for h2 in winnersoup.findAll(\"h2\", \"subheadline\")]\n",
      "    runners_up = [h2.parent.li.string for h2 in winnersoup.findAll(\"h2\",\"heading\")]\n",
      "    return {\"category\": category,\n",
      "            \"category_url\": winnerurl,\n",
      "            \"winner\": winner,\n",
      "            \"runners_up\": runners_up}\n",
      "\n",
      "get_category_winner('http://www.chicagoreader.com/chicago/best-fancy-restaurant/BestOf?oid=13794959')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_category_winners(category,year='2014'):\n",
      "    \"\"\" \"\"\"\n",
      "    data = [] # a list to store our dictionaries\n",
      "    for winnerurl in get_category_links(category,year):\n",
      "        winner = get_category_winner(winnerurl)\n",
      "        #winner = get_category_winner('http://www.chicagoreader.com/chicago/best-fancy-restaurant/BestOf?oid=13794959')\n",
      "        data.append(winner)\n",
      "        sleep(1) # let's be nice and not hit that website too hard!\n",
      "    return data\n",
      "\n",
      "# Now run make the final command for this tutorial, taking advantage of all the above\n",
      "# CAUTION: this command issues a large number of hits to the target website\n",
      "# As seen in the get_category_winners function a 1 second delay is introduced between each hit\n",
      "# Be prepared for this to take a considerable time to run. \n",
      "# Please be considerate and keep a reasonable value for sleep, \n",
      "# if you are going to generate a large number of hits on the target website\n",
      "get_category_winners('CityLife','2014')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# THIS WAS NOT USED, BUT MAY BE GOOD TO KNOW\n",
      "# a filter function can be defined and the used in a find_all method\n",
      "def has_id_BestOfWinnerList(tag):\n",
      "    \"\"\"\"filter function, returns true if given tag has id equal to 'BestOfWinnerList'\"\"\"\n",
      "    return tag.has_attr('id') and tag['id']=='BestOfWinnerList'\n",
      "\n",
      "testhtml = \"\"\"\n",
      "<html><head><title>The Dormouse's story</title></head>\n",
      "<body>\n",
      "<span id='BestOfWinnerList'>you found me</span>\n",
      "<span id='WorstOfWinnerList'>these are not the winners you are looking for</span>\n",
      "<span >My Id was stolen</span>\n",
      "</body>\n",
      "\"\"\"\n",
      "testsoup=BeautifulSoup(testhtml)\n",
      "print testsoup.findAll('span')\n",
      "print testsoup.findAll(has_id_BestOfWinnerList)\n",
      "testsoup.findAll(has_id_BestOfWinnerList)[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}